{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Import Dependencies\nimport numpy\nimport sys\nimport nltk\nnltk.download('stopwords')\nfrom nltk.tokenize import RegexpTokenizer\nfrom nltk.corpus import stopwords\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, LSTM\nfrom keras.utils import np_utils\nfrom keras.callbacks import ModelCheckpoint","metadata":{"execution":{"iopub.status.busy":"2022-07-27T06:02:23.363177Z","iopub.execute_input":"2022-07-27T06:02:23.363592Z","iopub.status.idle":"2022-07-27T06:02:29.561044Z","shell.execute_reply.started":"2022-07-27T06:02:23.363508Z","shell.execute_reply":"2022-07-27T06:02:29.560054Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"# load data\n# loading data and opening our input data in the form of a txt file\n# Project Gutenburg/berg is where the data can be found\nfile=open(\"../input/frankenstein/frankenstein.txt\").read()","metadata":{"execution":{"iopub.status.busy":"2022-07-27T06:02:29.562757Z","iopub.execute_input":"2022-07-27T06:02:29.563303Z","iopub.status.idle":"2022-07-27T06:02:29.578221Z","shell.execute_reply.started":"2022-07-27T06:02:29.563276Z","shell.execute_reply":"2022-07-27T06:02:29.577390Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# tokenization\n# standardization\n#what is tokenization? Tokenization is the process of breaking a stream of text up into words phrases symbols or some meaningful elements\ndef tokenize_words(input):\n    input=input.lower()\n    tokenizer=RegexpTokenizer(r'\\w+')\n    tokens=tokenizer.tokenize(input)\n    filtered=filter(lambda token: token not in stopwords.words('english'), tokens)\n    return \" \".join(filtered)\nprocessed_inputs=tokenize_words(file)","metadata":{"execution":{"iopub.status.busy":"2022-07-27T06:02:29.581286Z","iopub.execute_input":"2022-07-27T06:02:29.581554Z","iopub.status.idle":"2022-07-27T06:02:38.511303Z","shell.execute_reply.started":"2022-07-27T06:02:29.581530Z","shell.execute_reply":"2022-07-27T06:02:38.510379Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#chara to numbers\nchars=sorted(list(set(processed_inputs)))\nchar_to_num=dict((c,i) for i,c in enumerate(chars))","metadata":{"execution":{"iopub.status.busy":"2022-07-27T06:02:38.514057Z","iopub.execute_input":"2022-07-27T06:02:38.514464Z","iopub.status.idle":"2022-07-27T06:02:38.524984Z","shell.execute_reply.started":"2022-07-27T06:02:38.514421Z","shell.execute_reply":"2022-07-27T06:02:38.521813Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#check if the words to char or chars to num has worked\ninput_len=len(processed_inputs)\nvocab_len=len(chars)\nprint(\"Total number of characters:\", input_len)\nprint(\"Total vocab:\",vocab_len)","metadata":{"execution":{"iopub.status.busy":"2022-07-27T06:02:38.526480Z","iopub.execute_input":"2022-07-27T06:02:38.526841Z","iopub.status.idle":"2022-07-27T06:02:38.541569Z","shell.execute_reply.started":"2022-07-27T06:02:38.526805Z","shell.execute_reply":"2022-07-27T06:02:38.540324Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Total number of characters: 269566\nTotal vocab: 38\n","output_type":"stream"}]},{"cell_type":"code","source":"#sege length\nseq_length=100\nx_data=[]\ny_data=[]","metadata":{"execution":{"iopub.status.busy":"2022-07-27T06:02:38.543007Z","iopub.execute_input":"2022-07-27T06:02:38.543638Z","iopub.status.idle":"2022-07-27T06:02:38.551490Z","shell.execute_reply.started":"2022-07-27T06:02:38.543601Z","shell.execute_reply":"2022-07-27T06:02:38.550669Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#loop through the sequence\nfor i in range(0,input_len-seq_length,1):\n    in_seq=processed_inputs[i:i+seq_length]\n    out_seq=processed_inputs[i+seq_length]\n    x_data.append([char_to_num[char] for char in in_seq])\n    y_data.append(char_to_num[out_seq])\n    \nn_patterns=len(x_data)\nprint(\"Total Patterns:\", n_patterns)","metadata":{"execution":{"iopub.status.busy":"2022-07-27T06:02:38.553039Z","iopub.execute_input":"2022-07-27T06:02:38.553470Z","iopub.status.idle":"2022-07-27T06:02:41.034875Z","shell.execute_reply.started":"2022-07-27T06:02:38.553346Z","shell.execute_reply":"2022-07-27T06:02:41.033865Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Total Patterns: 269466\n","output_type":"stream"}]},{"cell_type":"code","source":"# convert input sequence to np array and so on\nX=numpy.reshape(x_data,(n_patterns, seq_length,1))\nX=X/float(vocab_len)","metadata":{"execution":{"iopub.status.busy":"2022-07-27T06:02:41.036491Z","iopub.execute_input":"2022-07-27T06:02:41.036863Z","iopub.status.idle":"2022-07-27T06:02:44.435668Z","shell.execute_reply.started":"2022-07-27T06:02:41.036826Z","shell.execute_reply":"2022-07-27T06:02:44.434586Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# One-hot encoding\ny=np_utils.to_categorical(y_data)","metadata":{"execution":{"iopub.status.busy":"2022-07-27T06:02:44.436970Z","iopub.execute_input":"2022-07-27T06:02:44.438703Z","iopub.status.idle":"2022-07-27T06:02:44.489309Z","shell.execute_reply.started":"2022-07-27T06:02:44.438660Z","shell.execute_reply":"2022-07-27T06:02:44.488407Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#Creating the model\nmodel=Sequential()\nmodel.add(LSTM(256, input_shape=(X.shape[1],X.shape[2]), return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(256, return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(256))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(y.shape[1],activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2022-07-27T06:02:44.493819Z","iopub.execute_input":"2022-07-27T06:02:44.494647Z","iopub.status.idle":"2022-07-27T06:02:48.066954Z","shell.execute_reply.started":"2022-07-27T06:02:44.494606Z","shell.execute_reply":"2022-07-27T06:02:48.066010Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"2022-07-27 06:02:44.576114: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-07-27 06:02:44.697261: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-07-27 06:02:44.698100: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-07-27 06:02:44.699827: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-07-27 06:02:44.700142: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-07-27 06:02:44.700866: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-07-27 06:02:44.701530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-07-27 06:02:46.870666: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-07-27 06:02:46.872086: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-07-27 06:02:46.873252: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-07-27 06:02:46.874483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}]},{"cell_type":"code","source":"#Compile the model\nmodel.compile(loss='categorical_crossentropy',optimizer='adam')","metadata":{"execution":{"iopub.status.busy":"2022-07-27T06:02:48.068321Z","iopub.execute_input":"2022-07-27T06:02:48.068677Z","iopub.status.idle":"2022-07-27T06:02:48.088706Z","shell.execute_reply.started":"2022-07-27T06:02:48.068643Z","shell.execute_reply":"2022-07-27T06:02:48.087873Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#saving the weights\nfilepath='model_weights_saved.hdf5'\ncheckpoint=ModelCheckpoint(filepath, monitor='loss',verbose=1,save_best_only=True,mode='min')\ndesired_callbacks=[checkpoint]","metadata":{"execution":{"iopub.status.busy":"2022-07-27T06:02:48.089906Z","iopub.execute_input":"2022-07-27T06:02:48.090328Z","iopub.status.idle":"2022-07-27T06:02:48.095793Z","shell.execute_reply.started":"2022-07-27T06:02:48.090291Z","shell.execute_reply":"2022-07-27T06:02:48.094641Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#fit the model and let it train\nmodel.fit(X,y,epochs=10,batch_size=256,callbacks=desired_callbacks)","metadata":{"execution":{"iopub.status.busy":"2022-07-27T06:02:48.097551Z","iopub.execute_input":"2022-07-27T06:02:48.098240Z","iopub.status.idle":"2022-07-27T06:14:13.933344Z","shell.execute_reply.started":"2022-07-27T06:02:48.098205Z","shell.execute_reply":"2022-07-27T06:14:13.932383Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"2022-07-27 06:02:48.444967: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"2022-07-27 06:02:52.827949: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"name":"stdout","text":"1053/1053 [==============================] - 72s 63ms/step - loss: 2.7874\n\nEpoch 00001: loss improved from inf to 2.78743, saving model to model_weights_saved.hdf5\nEpoch 2/10\n1053/1053 [==============================] - 66s 62ms/step - loss: 2.4565\n\nEpoch 00002: loss improved from 2.78743 to 2.45650, saving model to model_weights_saved.hdf5\nEpoch 3/10\n1053/1053 [==============================] - 66s 63ms/step - loss: 2.2023\n\nEpoch 00003: loss improved from 2.45650 to 2.20228, saving model to model_weights_saved.hdf5\nEpoch 4/10\n1053/1053 [==============================] - 66s 63ms/step - loss: 2.0206\n\nEpoch 00004: loss improved from 2.20228 to 2.02055, saving model to model_weights_saved.hdf5\nEpoch 5/10\n1053/1053 [==============================] - 66s 63ms/step - loss: 1.9013\n\nEpoch 00005: loss improved from 2.02055 to 1.90130, saving model to model_weights_saved.hdf5\nEpoch 6/10\n1053/1053 [==============================] - 66s 63ms/step - loss: 1.8219\n\nEpoch 00006: loss improved from 1.90130 to 1.82192, saving model to model_weights_saved.hdf5\nEpoch 7/10\n1053/1053 [==============================] - 66s 63ms/step - loss: 1.7616\n\nEpoch 00007: loss improved from 1.82192 to 1.76161, saving model to model_weights_saved.hdf5\nEpoch 8/10\n1053/1053 [==============================] - 66s 63ms/step - loss: 1.7127\n\nEpoch 00008: loss improved from 1.76161 to 1.71275, saving model to model_weights_saved.hdf5\nEpoch 9/10\n1053/1053 [==============================] - 66s 63ms/step - loss: 1.6782\n\nEpoch 00009: loss improved from 1.71275 to 1.67817, saving model to model_weights_saved.hdf5\nEpoch 10/10\n1053/1053 [==============================] - 66s 63ms/step - loss: 1.6465\n\nEpoch 00010: loss improved from 1.67817 to 1.64654, saving model to model_weights_saved.hdf5\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f5de37bb510>"},"metadata":{}}]},{"cell_type":"code","source":"#recompile the model with saved weights\nfilename='model_weights_saved.hdf5'\nmodel.load_weights(filename)\nmodel.compile(loss='categorical_crossentropy',optimizer='adam')","metadata":{"execution":{"iopub.status.busy":"2022-07-27T06:14:13.934956Z","iopub.execute_input":"2022-07-27T06:14:13.935332Z","iopub.status.idle":"2022-07-27T06:14:13.963732Z","shell.execute_reply.started":"2022-07-27T06:14:13.935295Z","shell.execute_reply":"2022-07-27T06:14:13.962857Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# output of the models back into characters\nnum_to_char=dict((i,c) for i,c in enumerate(chars))","metadata":{"execution":{"iopub.status.busy":"2022-07-27T06:14:13.965168Z","iopub.execute_input":"2022-07-27T06:14:13.965537Z","iopub.status.idle":"2022-07-27T06:14:13.972662Z","shell.execute_reply.started":"2022-07-27T06:14:13.965502Z","shell.execute_reply":"2022-07-27T06:14:13.971778Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#random seed to help generate\nstart=numpy.random.randint(0,len(x_data)-1)\npattern=x_data[start]\nprint(\"Random Seed :\")\nprint(\"\\\"\",''.join([num_to_char[value] for value in pattern]),\"\\\"\")","metadata":{"execution":{"iopub.status.busy":"2022-07-27T06:14:13.973907Z","iopub.execute_input":"2022-07-27T06:14:13.974444Z","iopub.status.idle":"2022-07-27T06:14:13.982569Z","shell.execute_reply.started":"2022-07-27T06:14:13.974408Z","shell.execute_reply":"2022-07-27T06:14:13.981589Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Random Seed :\n\" sh combined disdain malignity unearthly ugliness rendered almost horrible human eyes scarcely observ \"\n","output_type":"stream"}]},{"cell_type":"code","source":"# generate the text\nfor i in range(1000):\n    x=numpy.reshape(pattern,(1,len(pattern),1))\n    x=x/float(vocab_len)\n    prediction=model.predict(x, verbose=0)\n    index=numpy.argmax(prediction)\n    result=num_to_char[index]\n    seg_in=[num_to_char[value] for value in pattern]\n    sys.stdout.write(result)\n    pattern.append(index)\n    pattern=pattern[1:len(pattern)]","metadata":{"execution":{"iopub.status.busy":"2022-07-27T06:14:13.984194Z","iopub.execute_input":"2022-07-27T06:14:13.984943Z","iopub.status.idle":"2022-07-27T06:14:54.838477Z","shell.execute_reply.started":"2022-07-27T06:14:13.984903Z","shell.execute_reply":"2022-07-27T06:14:54.837411Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"ed see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see s","output_type":"stream"}]},{"cell_type":"markdown","source":"The End","metadata":{}}]}
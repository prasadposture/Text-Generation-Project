{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/prasadposture121/text-generation-project?scriptVersionId=101858496\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"#Import Dependencies\nimport numpy\nimport sys\nimport nltk\nnltk.download('stopwords')\nfrom nltk.tokenize import RegexpTokenizer\nfrom nltk.corpus import stopwords\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, LSTM\nfrom keras.utils import np_utils\nfrom keras.callbacks import ModelCheckpoint","metadata":{"execution":{"iopub.status.busy":"2022-07-27T07:07:44.03845Z","iopub.execute_input":"2022-07-27T07:07:44.039087Z","iopub.status.idle":"2022-07-27T07:07:50.409121Z","shell.execute_reply.started":"2022-07-27T07:07:44.038981Z","shell.execute_reply":"2022-07-27T07:07:50.408151Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"# load data\n# loading data and opening our input data in the form of a txt file\n# Project Gutenburg/berg is where the data can be found\nfile=open(\"../input/frankenstein/frankenstein.txt\").read()","metadata":{"execution":{"iopub.status.busy":"2022-07-27T07:07:50.411271Z","iopub.execute_input":"2022-07-27T07:07:50.411932Z","iopub.status.idle":"2022-07-27T07:07:50.427898Z","shell.execute_reply.started":"2022-07-27T07:07:50.411894Z","shell.execute_reply":"2022-07-27T07:07:50.427056Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# tokenization\n# standardization\n#what is tokenization? Tokenization is the process of breaking a stream of text up into words phrases symbols or some meaningful elements\ndef tokenize_words(input):\n    input=input.lower()\n    tokenizer=RegexpTokenizer(r'\\w+')\n    tokens=tokenizer.tokenize(input)\n    filtered=filter(lambda token: token not in stopwords.words('english'), tokens)\n    return \" \".join(filtered)\nprocessed_inputs=tokenize_words(file)","metadata":{"execution":{"iopub.status.busy":"2022-07-27T07:07:50.429283Z","iopub.execute_input":"2022-07-27T07:07:50.429619Z","iopub.status.idle":"2022-07-27T07:07:59.332749Z","shell.execute_reply.started":"2022-07-27T07:07:50.429585Z","shell.execute_reply":"2022-07-27T07:07:59.331777Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#chara to numbers\nchars=sorted(list(set(processed_inputs)))\nchar_to_num=dict((c,i) for i,c in enumerate(chars))","metadata":{"execution":{"iopub.status.busy":"2022-07-27T07:07:59.335072Z","iopub.execute_input":"2022-07-27T07:07:59.335342Z","iopub.status.idle":"2022-07-27T07:07:59.342865Z","shell.execute_reply.started":"2022-07-27T07:07:59.335318Z","shell.execute_reply":"2022-07-27T07:07:59.341765Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#check if the words to char or chars to num has worked\ninput_len=len(processed_inputs)\nvocab_len=len(chars)\nprint(\"Total number of characters:\", input_len)\nprint(\"Total vocab:\",vocab_len)","metadata":{"execution":{"iopub.status.busy":"2022-07-27T07:07:59.344439Z","iopub.execute_input":"2022-07-27T07:07:59.345416Z","iopub.status.idle":"2022-07-27T07:07:59.353484Z","shell.execute_reply.started":"2022-07-27T07:07:59.34538Z","shell.execute_reply":"2022-07-27T07:07:59.352438Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Total number of characters: 269566\nTotal vocab: 38\n","output_type":"stream"}]},{"cell_type":"code","source":"#sege length\nseq_length=100\nx_data=[]\ny_data=[]","metadata":{"execution":{"iopub.status.busy":"2022-07-27T07:07:59.354829Z","iopub.execute_input":"2022-07-27T07:07:59.355417Z","iopub.status.idle":"2022-07-27T07:07:59.362212Z","shell.execute_reply.started":"2022-07-27T07:07:59.355382Z","shell.execute_reply":"2022-07-27T07:07:59.361301Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#loop through the sequence\nfor i in range(0,input_len-seq_length,1):\n    in_seq=processed_inputs[i:i+seq_length]\n    out_seq=processed_inputs[i+seq_length]\n    x_data.append([char_to_num[char] for char in in_seq])\n    y_data.append(char_to_num[out_seq])\n    \nn_patterns=len(x_data)\nprint(\"Total Patterns:\", n_patterns)","metadata":{"execution":{"iopub.status.busy":"2022-07-27T07:07:59.363631Z","iopub.execute_input":"2022-07-27T07:07:59.364079Z","iopub.status.idle":"2022-07-27T07:08:02.479881Z","shell.execute_reply.started":"2022-07-27T07:07:59.364046Z","shell.execute_reply":"2022-07-27T07:08:02.478873Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Total Patterns: 269466\n","output_type":"stream"}]},{"cell_type":"code","source":"# convert input sequence to np array and so on\nX=numpy.reshape(x_data,(n_patterns, seq_length,1))\nX=X/float(vocab_len)","metadata":{"execution":{"iopub.status.busy":"2022-07-27T07:08:02.481234Z","iopub.execute_input":"2022-07-27T07:08:02.481907Z","iopub.status.idle":"2022-07-27T07:08:05.973688Z","shell.execute_reply.started":"2022-07-27T07:08:02.48187Z","shell.execute_reply":"2022-07-27T07:08:05.972695Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# One-hot encoding\ny=np_utils.to_categorical(y_data)","metadata":{"execution":{"iopub.status.busy":"2022-07-27T07:08:05.975444Z","iopub.execute_input":"2022-07-27T07:08:05.975824Z","iopub.status.idle":"2022-07-27T07:08:06.027891Z","shell.execute_reply.started":"2022-07-27T07:08:05.975771Z","shell.execute_reply":"2022-07-27T07:08:06.026958Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#Creating the model\nmodel=Sequential()\nmodel.add(LSTM(256, input_shape=(X.shape[1],X.shape[2]), return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(256, return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(256))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(y.shape[1],activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2022-07-27T07:08:06.031689Z","iopub.execute_input":"2022-07-27T07:08:06.032009Z","iopub.status.idle":"2022-07-27T07:08:09.59474Z","shell.execute_reply.started":"2022-07-27T07:08:06.031983Z","shell.execute_reply":"2022-07-27T07:08:09.593736Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"2022-07-27 07:08:06.123182: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-07-27 07:08:06.260013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-07-27 07:08:06.260785: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-07-27 07:08:06.262114: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-07-27 07:08:06.262435: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-07-27 07:08:06.263185: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-07-27 07:08:06.263829: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-07-27 07:08:08.578939: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-07-27 07:08:08.579773: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-07-27 07:08:08.580471: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-07-27 07:08:08.581083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}]},{"cell_type":"code","source":"#Compile the model\nmodel.compile(loss='categorical_crossentropy',optimizer='adam')","metadata":{"execution":{"iopub.status.busy":"2022-07-27T07:08:09.596321Z","iopub.execute_input":"2022-07-27T07:08:09.596715Z","iopub.status.idle":"2022-07-27T07:08:09.615263Z","shell.execute_reply.started":"2022-07-27T07:08:09.596677Z","shell.execute_reply":"2022-07-27T07:08:09.614432Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#saving the weights\nfilepath='model_weights_saved.hdf5'\ncheckpoint=ModelCheckpoint(filepath, monitor='loss',verbose=1,save_best_only=True,mode='min')\ndesired_callbacks=[checkpoint]","metadata":{"execution":{"iopub.status.busy":"2022-07-27T07:08:09.616457Z","iopub.execute_input":"2022-07-27T07:08:09.616885Z","iopub.status.idle":"2022-07-27T07:08:09.624327Z","shell.execute_reply.started":"2022-07-27T07:08:09.61685Z","shell.execute_reply":"2022-07-27T07:08:09.623385Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#fit the model and let it train\nmodel.fit(X,y,epochs=10,batch_size=256,callbacks=desired_callbacks)","metadata":{"execution":{"iopub.status.busy":"2022-07-27T07:08:09.625819Z","iopub.execute_input":"2022-07-27T07:08:09.626685Z","iopub.status.idle":"2022-07-27T07:19:34.990714Z","shell.execute_reply.started":"2022-07-27T07:08:09.626651Z","shell.execute_reply":"2022-07-27T07:19:34.989813Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"2022-07-27 07:08:09.974119: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"2022-07-27 07:08:14.057128: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"name":"stdout","text":"1053/1053 [==============================] - 71s 62ms/step - loss: 2.7652\n\nEpoch 00001: loss improved from inf to 2.76518, saving model to model_weights_saved.hdf5\nEpoch 2/10\n1053/1053 [==============================] - 66s 62ms/step - loss: 2.4276\n\nEpoch 00002: loss improved from 2.76518 to 2.42755, saving model to model_weights_saved.hdf5\nEpoch 3/10\n1053/1053 [==============================] - 66s 63ms/step - loss: 2.1707\n\nEpoch 00003: loss improved from 2.42755 to 2.17065, saving model to model_weights_saved.hdf5\nEpoch 4/10\n1053/1053 [==============================] - 66s 63ms/step - loss: 1.9995\n\nEpoch 00004: loss improved from 2.17065 to 1.99952, saving model to model_weights_saved.hdf5\nEpoch 5/10\n1053/1053 [==============================] - 66s 63ms/step - loss: 1.8855\n\nEpoch 00005: loss improved from 1.99952 to 1.88548, saving model to model_weights_saved.hdf5\nEpoch 6/10\n1053/1053 [==============================] - 66s 63ms/step - loss: 1.8087\n\nEpoch 00006: loss improved from 1.88548 to 1.80870, saving model to model_weights_saved.hdf5\nEpoch 7/10\n1053/1053 [==============================] - 66s 63ms/step - loss: 1.7510\n\nEpoch 00007: loss improved from 1.80870 to 1.75104, saving model to model_weights_saved.hdf5\nEpoch 8/10\n1053/1053 [==============================] - 66s 63ms/step - loss: 1.7054\n\nEpoch 00008: loss improved from 1.75104 to 1.70536, saving model to model_weights_saved.hdf5\nEpoch 9/10\n1053/1053 [==============================] - 66s 63ms/step - loss: 1.6668\n\nEpoch 00009: loss improved from 1.70536 to 1.66681, saving model to model_weights_saved.hdf5\nEpoch 10/10\n1053/1053 [==============================] - 66s 63ms/step - loss: 1.6337\n\nEpoch 00010: loss improved from 1.66681 to 1.63374, saving model to model_weights_saved.hdf5\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7ff148d87450>"},"metadata":{}}]},{"cell_type":"code","source":"#recompile the model with saved weights\nfilename='model_weights_saved.hdf5'\nmodel.load_weights(filename)\nmodel.compile(loss='categorical_crossentropy',optimizer='adam')","metadata":{"execution":{"iopub.status.busy":"2022-07-27T07:19:34.992263Z","iopub.execute_input":"2022-07-27T07:19:34.992628Z","iopub.status.idle":"2022-07-27T07:19:35.020337Z","shell.execute_reply.started":"2022-07-27T07:19:34.992593Z","shell.execute_reply":"2022-07-27T07:19:35.019477Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# output of the models back into characters\nnum_to_char=dict((i,c) for i,c in enumerate(chars))","metadata":{"execution":{"iopub.status.busy":"2022-07-27T07:19:35.021575Z","iopub.execute_input":"2022-07-27T07:19:35.02193Z","iopub.status.idle":"2022-07-27T07:19:35.028077Z","shell.execute_reply.started":"2022-07-27T07:19:35.021896Z","shell.execute_reply":"2022-07-27T07:19:35.026282Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#random seed to help generate\nstart=numpy.random.randint(0,len(x_data)-1)\npattern=x_data[start]\nprint(\"Random Seed :\")\nprint(\"\\\"\",''.join([num_to_char[value] for value in pattern]),\"\\\"\")","metadata":{"execution":{"iopub.status.busy":"2022-07-27T07:19:35.02977Z","iopub.execute_input":"2022-07-27T07:19:35.030145Z","iopub.status.idle":"2022-07-27T07:19:35.040185Z","shell.execute_reply.started":"2022-07-27T07:19:35.03011Z","shell.execute_reply":"2022-07-27T07:19:35.039226Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Random Seed :\n\" idual project gutenberg tm electronic work derived public domain contain notice indicating posted pe \"\n","output_type":"stream"}]},{"cell_type":"code","source":"# generate the text\nfor i in range(1000):\n    x=numpy.reshape(pattern,(1,len(pattern),1))\n    x=x/float(vocab_len)\n    prediction=model.predict(x, verbose=0)\n    index=numpy.argmax(prediction)\n    result=num_to_char[index]\n    seg_in=[num_to_char[value] for value in pattern]\n    sys.stdout.write(result)\n    pattern.append(index)\n    pattern=pattern[1:len(pattern)]","metadata":{"execution":{"iopub.status.busy":"2022-07-27T07:19:35.04125Z","iopub.execute_input":"2022-07-27T07:19:35.043636Z","iopub.status.idle":"2022-07-27T07:20:15.303441Z","shell.execute_reply.started":"2022-07-27T07:19:35.0436Z","shell.execute_reply":"2022-07-27T07:20:15.302484Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"rceived see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see ","output_type":"stream"}]},{"cell_type":"markdown","source":"The End","metadata":{}}]}
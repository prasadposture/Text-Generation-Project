{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/prasadposture121/text-generation-project?scriptVersionId=102747735\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","id":"4ca57dd9","metadata":{"papermill":{"duration":0.00824,"end_time":"2022-08-07T17:30:36.115538","exception":false,"start_time":"2022-08-07T17:30:36.107298","status":"completed"},"tags":[]},"source":["# Prasad Rajesh Posture <br>\n","Batch : July 2022 <br>\n","Artificial Intelligence <br>"]},{"cell_type":"markdown","id":"5b6da135","metadata":{"papermill":{"duration":0.004756,"end_time":"2022-08-07T17:30:36.125653","exception":false,"start_time":"2022-08-07T17:30:36.120897","status":"completed"},"tags":[]},"source":["**Task:** Create a deep learning model that generates meaningful text based on the input."]},{"cell_type":"code","execution_count":1,"id":"870286b0","metadata":{"execution":{"iopub.execute_input":"2022-08-07T17:30:36.137095Z","iopub.status.busy":"2022-08-07T17:30:36.136504Z","iopub.status.idle":"2022-08-07T17:30:44.814771Z","shell.execute_reply":"2022-08-07T17:30:44.813367Z"},"papermill":{"duration":8.688575,"end_time":"2022-08-07T17:30:44.818817","exception":false,"start_time":"2022-08-07T17:30:36.130242","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}],"source":["#Import Dependencies\n","import numpy\n","import sys\n","import nltk\n","nltk.download('stopwords')\n","from nltk.tokenize import RegexpTokenizer\n","from nltk.corpus import stopwords\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, LSTM\n","from keras.utils import np_utils\n","from keras.callbacks import ModelCheckpoint\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":2,"id":"4d632f6e","metadata":{"execution":{"iopub.execute_input":"2022-08-07T17:30:44.832933Z","iopub.status.busy":"2022-08-07T17:30:44.832261Z","iopub.status.idle":"2022-08-07T17:30:44.857243Z","shell.execute_reply":"2022-08-07T17:30:44.855979Z"},"papermill":{"duration":0.035085,"end_time":"2022-08-07T17:30:44.860089","exception":false,"start_time":"2022-08-07T17:30:44.825004","status":"completed"},"tags":[]},"outputs":[],"source":["# load data\n","# loading data and opening our input data in the form of a txt file\n","# Project Gutenburg/berg is where the data can be found\n","file=open(\"../input/frankenstein/frankenstein.txt\").read()"]},{"cell_type":"code","execution_count":3,"id":"78257f3c","metadata":{"execution":{"iopub.execute_input":"2022-08-07T17:30:44.873422Z","iopub.status.busy":"2022-08-07T17:30:44.872365Z","iopub.status.idle":"2022-08-07T17:30:57.186974Z","shell.execute_reply":"2022-08-07T17:30:57.18573Z"},"papermill":{"duration":12.325239,"end_time":"2022-08-07T17:30:57.190867","exception":false,"start_time":"2022-08-07T17:30:44.865628","status":"completed"},"tags":[]},"outputs":[],"source":["# tokenization\n","# standardization\n","#what is tokenization? Tokenization is the process of breaking a stream of text up into words phrases symbols or some meaningful elements\n","def tokenize_words(input):\n","    input=input.lower()\n","    tokenizer=RegexpTokenizer(r'\\w+')\n","    tokens=tokenizer.tokenize(input)\n","    filtered=filter(lambda token: token not in stopwords.words('english'), tokens)\n","    return \" \".join(filtered)\n","processed_inputs=tokenize_words(file)"]},{"cell_type":"code","execution_count":4,"id":"fa10af75","metadata":{"execution":{"iopub.execute_input":"2022-08-07T17:30:57.210466Z","iopub.status.busy":"2022-08-07T17:30:57.209733Z","iopub.status.idle":"2022-08-07T17:30:57.224007Z","shell.execute_reply":"2022-08-07T17:30:57.222616Z"},"papermill":{"duration":0.028072,"end_time":"2022-08-07T17:30:57.227531","exception":false,"start_time":"2022-08-07T17:30:57.199459","status":"completed"},"tags":[]},"outputs":[],"source":["#chara to numbers\n","chars=sorted(list(set(processed_inputs)))\n","char_to_num=dict((c,i) for i,c in enumerate(chars))"]},{"cell_type":"code","execution_count":5,"id":"b3219811","metadata":{"execution":{"iopub.execute_input":"2022-08-07T17:30:57.247176Z","iopub.status.busy":"2022-08-07T17:30:57.246594Z","iopub.status.idle":"2022-08-07T17:30:57.256986Z","shell.execute_reply":"2022-08-07T17:30:57.25504Z"},"papermill":{"duration":0.029792,"end_time":"2022-08-07T17:30:57.26577","exception":false,"start_time":"2022-08-07T17:30:57.235978","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Total number of characters: 269566\n","Total vocab: 38\n"]}],"source":["#check if the words to char or chars to num has worked\n","input_len=len(processed_inputs)\n","vocab_len=len(chars)\n","print(\"Total number of characters:\", input_len)\n","print(\"Total vocab:\",vocab_len)"]},{"cell_type":"code","execution_count":6,"id":"5ed62423","metadata":{"execution":{"iopub.execute_input":"2022-08-07T17:30:57.289641Z","iopub.status.busy":"2022-08-07T17:30:57.289163Z","iopub.status.idle":"2022-08-07T17:30:57.295272Z","shell.execute_reply":"2022-08-07T17:30:57.293854Z"},"papermill":{"duration":0.02602,"end_time":"2022-08-07T17:30:57.298394","exception":false,"start_time":"2022-08-07T17:30:57.272374","status":"completed"},"tags":[]},"outputs":[],"source":["#sege length\n","seq_length=100\n","x_data=[]\n","y_data=[]"]},{"cell_type":"code","execution_count":7,"id":"d7770c3b","metadata":{"execution":{"iopub.execute_input":"2022-08-07T17:30:57.312561Z","iopub.status.busy":"2022-08-07T17:30:57.310957Z","iopub.status.idle":"2022-08-07T17:31:01.299241Z","shell.execute_reply":"2022-08-07T17:31:01.297651Z"},"papermill":{"duration":3.998467,"end_time":"2022-08-07T17:31:01.302346","exception":false,"start_time":"2022-08-07T17:30:57.303879","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Total Patterns: 269466\n"]}],"source":["#loop through the sequence\n","for i in range(0,input_len-seq_length,1):\n","    in_seq=processed_inputs[i:i+seq_length]\n","    out_seq=processed_inputs[i+seq_length]\n","    x_data.append([char_to_num[char] for char in in_seq])\n","    y_data.append(char_to_num[out_seq])\n","    \n","n_patterns=len(x_data)\n","print(\"Total Patterns:\", n_patterns)"]},{"cell_type":"code","execution_count":8,"id":"0696d73b","metadata":{"execution":{"iopub.execute_input":"2022-08-07T17:31:01.31731Z","iopub.status.busy":"2022-08-07T17:31:01.31585Z","iopub.status.idle":"2022-08-07T17:31:03.741214Z","shell.execute_reply":"2022-08-07T17:31:03.739931Z"},"papermill":{"duration":2.436294,"end_time":"2022-08-07T17:31:03.744459","exception":false,"start_time":"2022-08-07T17:31:01.308165","status":"completed"},"tags":[]},"outputs":[],"source":["# convert input sequence to np array and so on\n","X=numpy.reshape(x_data,(n_patterns, seq_length,1))\n","X=X/float(vocab_len)"]},{"cell_type":"code","execution_count":9,"id":"e9a67ffb","metadata":{"execution":{"iopub.execute_input":"2022-08-07T17:31:03.759355Z","iopub.status.busy":"2022-08-07T17:31:03.758422Z","iopub.status.idle":"2022-08-07T17:31:03.8148Z","shell.execute_reply":"2022-08-07T17:31:03.813519Z"},"papermill":{"duration":0.067249,"end_time":"2022-08-07T17:31:03.818011","exception":false,"start_time":"2022-08-07T17:31:03.750762","status":"completed"},"tags":[]},"outputs":[],"source":["# One-hot encoding\n","y=np_utils.to_categorical(y_data)"]},{"cell_type":"code","execution_count":10,"id":"15112948","metadata":{"execution":{"iopub.execute_input":"2022-08-07T17:31:03.83131Z","iopub.status.busy":"2022-08-07T17:31:03.830883Z","iopub.status.idle":"2022-08-07T17:31:08.564526Z","shell.execute_reply":"2022-08-07T17:31:08.563119Z"},"papermill":{"duration":4.743545,"end_time":"2022-08-07T17:31:08.567716","exception":false,"start_time":"2022-08-07T17:31:03.824171","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-08-07 17:31:03.939309: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-08-07 17:31:04.082428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-08-07 17:31:04.083511: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-08-07 17:31:04.085520: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2022-08-07 17:31:04.086036: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-08-07 17:31:04.087092: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-08-07 17:31:04.087931: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-08-07 17:31:06.862351: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-08-07 17:31:06.863424: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-08-07 17:31:06.864359: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-08-07 17:31:06.865139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"]}],"source":["#Creating the model\n","model=Sequential()\n","model.add(LSTM(256, input_shape=(X.shape[1],X.shape[2]), return_sequences=True))\n","model.add(Dropout(0.2))\n","model.add(LSTM(256, return_sequences=True))\n","model.add(Dropout(0.2))\n","model.add(LSTM(256))\n","model.add(Dropout(0.2))\n","model.add(Dense(y.shape[1],activation='softmax'))"]},{"cell_type":"code","execution_count":11,"id":"0e0ee7d2","metadata":{"execution":{"iopub.execute_input":"2022-08-07T17:31:08.581125Z","iopub.status.busy":"2022-08-07T17:31:08.580677Z","iopub.status.idle":"2022-08-07T17:31:08.607583Z","shell.execute_reply":"2022-08-07T17:31:08.606442Z"},"papermill":{"duration":0.037487,"end_time":"2022-08-07T17:31:08.610886","exception":false,"start_time":"2022-08-07T17:31:08.573399","status":"completed"},"tags":[]},"outputs":[],"source":["#Compile the model\n","model.compile(loss='categorical_crossentropy',optimizer='adam')"]},{"cell_type":"code","execution_count":12,"id":"724bc5ef","metadata":{"execution":{"iopub.execute_input":"2022-08-07T17:31:08.62567Z","iopub.status.busy":"2022-08-07T17:31:08.624491Z","iopub.status.idle":"2022-08-07T17:31:08.631792Z","shell.execute_reply":"2022-08-07T17:31:08.630159Z"},"papermill":{"duration":0.017873,"end_time":"2022-08-07T17:31:08.634706","exception":false,"start_time":"2022-08-07T17:31:08.616833","status":"completed"},"tags":[]},"outputs":[],"source":["#saving the weights\n","filepath='model_weights_saved.hdf5'\n","checkpoint=ModelCheckpoint(filepath, monitor='loss',verbose=1,save_best_only=True,mode='min')\n","desired_callbacks=[checkpoint]"]},{"cell_type":"code","execution_count":13,"id":"14df75d1","metadata":{"execution":{"iopub.execute_input":"2022-08-07T17:31:08.647867Z","iopub.status.busy":"2022-08-07T17:31:08.647088Z","iopub.status.idle":"2022-08-07T19:26:35.553518Z","shell.execute_reply":"2022-08-07T19:26:35.552088Z"},"papermill":{"duration":6926.916545,"end_time":"2022-08-07T19:26:35.556555","exception":false,"start_time":"2022-08-07T17:31:08.64001","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-08-07 17:31:09.113711: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n"]},{"name":"stderr","output_type":"stream","text":["2022-08-07 17:31:14.767940: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"]},{"name":"stdout","output_type":"stream","text":["1053/1053 [==============================] - 76s 65ms/step - loss: 2.7536\n","\n","Epoch 00001: loss improved from inf to 2.75363, saving model to model_weights_saved.hdf5\n","Epoch 2/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 2.4211\n","\n","Epoch 00002: loss improved from 2.75363 to 2.42112, saving model to model_weights_saved.hdf5\n","Epoch 3/100\n","1053/1053 [==============================] - 68s 65ms/step - loss: 2.1517\n","\n","Epoch 00003: loss improved from 2.42112 to 2.15167, saving model to model_weights_saved.hdf5\n","Epoch 4/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.9769\n","\n","Epoch 00004: loss improved from 2.15167 to 1.97686, saving model to model_weights_saved.hdf5\n","Epoch 5/100\n","1053/1053 [==============================] - 68s 65ms/step - loss: 1.8654\n","\n","Epoch 00005: loss improved from 1.97686 to 1.86545, saving model to model_weights_saved.hdf5\n","Epoch 6/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.7882\n","\n","Epoch 00006: loss improved from 1.86545 to 1.78820, saving model to model_weights_saved.hdf5\n","Epoch 7/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.7294\n","\n","Epoch 00007: loss improved from 1.78820 to 1.72943, saving model to model_weights_saved.hdf5\n","Epoch 8/100\n","1053/1053 [==============================] - 68s 65ms/step - loss: 1.6874\n","\n","Epoch 00008: loss improved from 1.72943 to 1.68737, saving model to model_weights_saved.hdf5\n","Epoch 9/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.6514\n","\n","Epoch 00009: loss improved from 1.68737 to 1.65140, saving model to model_weights_saved.hdf5\n","Epoch 10/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.6198\n","\n","Epoch 00010: loss improved from 1.65140 to 1.61983, saving model to model_weights_saved.hdf5\n","Epoch 11/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.5950\n","\n","Epoch 00011: loss improved from 1.61983 to 1.59502, saving model to model_weights_saved.hdf5\n","Epoch 12/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.5711\n","\n","Epoch 00012: loss improved from 1.59502 to 1.57107, saving model to model_weights_saved.hdf5\n","Epoch 13/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.5476\n","\n","Epoch 00013: loss improved from 1.57107 to 1.54757, saving model to model_weights_saved.hdf5\n","Epoch 14/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.5299\n","\n","Epoch 00014: loss improved from 1.54757 to 1.52987, saving model to model_weights_saved.hdf5\n","Epoch 15/100\n","1053/1053 [==============================] - 69s 66ms/step - loss: 1.5141\n","\n","Epoch 00015: loss improved from 1.52987 to 1.51408, saving model to model_weights_saved.hdf5\n","Epoch 16/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.4996\n","\n","Epoch 00016: loss improved from 1.51408 to 1.49963, saving model to model_weights_saved.hdf5\n","Epoch 17/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.4902\n","\n","Epoch 00017: loss improved from 1.49963 to 1.49017, saving model to model_weights_saved.hdf5\n","Epoch 18/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.4735\n","\n","Epoch 00018: loss improved from 1.49017 to 1.47349, saving model to model_weights_saved.hdf5\n","Epoch 19/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.4663\n","\n","Epoch 00019: loss improved from 1.47349 to 1.46633, saving model to model_weights_saved.hdf5\n","Epoch 20/100\n","1053/1053 [==============================] - 68s 65ms/step - loss: 1.4529\n","\n","Epoch 00020: loss improved from 1.46633 to 1.45289, saving model to model_weights_saved.hdf5\n","Epoch 21/100\n","1053/1053 [==============================] - 68s 65ms/step - loss: 1.4406\n","\n","Epoch 00021: loss improved from 1.45289 to 1.44062, saving model to model_weights_saved.hdf5\n","Epoch 22/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.4350\n","\n","Epoch 00022: loss improved from 1.44062 to 1.43499, saving model to model_weights_saved.hdf5\n","Epoch 23/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.4253\n","\n","Epoch 00023: loss improved from 1.43499 to 1.42530, saving model to model_weights_saved.hdf5\n","Epoch 24/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.4149\n","\n","Epoch 00024: loss improved from 1.42530 to 1.41493, saving model to model_weights_saved.hdf5\n","Epoch 25/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.4065\n","\n","Epoch 00025: loss improved from 1.41493 to 1.40651, saving model to model_weights_saved.hdf5\n","Epoch 26/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.4007\n","\n","Epoch 00026: loss improved from 1.40651 to 1.40070, saving model to model_weights_saved.hdf5\n","Epoch 27/100\n","1053/1053 [==============================] - 68s 65ms/step - loss: 1.3949\n","\n","Epoch 00027: loss improved from 1.40070 to 1.39492, saving model to model_weights_saved.hdf5\n","Epoch 28/100\n","1053/1053 [==============================] - 68s 65ms/step - loss: 1.3881\n","\n","Epoch 00028: loss improved from 1.39492 to 1.38810, saving model to model_weights_saved.hdf5\n","Epoch 29/100\n","1053/1053 [==============================] - 68s 65ms/step - loss: 1.3824\n","\n","Epoch 00029: loss improved from 1.38810 to 1.38240, saving model to model_weights_saved.hdf5\n","Epoch 30/100\n","1053/1053 [==============================] - 68s 65ms/step - loss: 1.3758\n","\n","Epoch 00030: loss improved from 1.38240 to 1.37575, saving model to model_weights_saved.hdf5\n","Epoch 31/100\n","1053/1053 [==============================] - 68s 65ms/step - loss: 1.3697\n","\n","Epoch 00031: loss improved from 1.37575 to 1.36967, saving model to model_weights_saved.hdf5\n","Epoch 32/100\n","1053/1053 [==============================] - 68s 65ms/step - loss: 1.3640\n","\n","Epoch 00032: loss improved from 1.36967 to 1.36401, saving model to model_weights_saved.hdf5\n","Epoch 33/100\n","1053/1053 [==============================] - 68s 65ms/step - loss: 1.3577\n","\n","Epoch 00033: loss improved from 1.36401 to 1.35773, saving model to model_weights_saved.hdf5\n","Epoch 34/100\n","1053/1053 [==============================] - 68s 65ms/step - loss: 1.3534\n","\n","Epoch 00034: loss improved from 1.35773 to 1.35344, saving model to model_weights_saved.hdf5\n","Epoch 35/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.3475\n","\n","Epoch 00035: loss improved from 1.35344 to 1.34748, saving model to model_weights_saved.hdf5\n","Epoch 36/100\n","1053/1053 [==============================] - 69s 66ms/step - loss: 1.3445\n","\n","Epoch 00036: loss improved from 1.34748 to 1.34453, saving model to model_weights_saved.hdf5\n","Epoch 37/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.3407\n","\n","Epoch 00037: loss improved from 1.34453 to 1.34071, saving model to model_weights_saved.hdf5\n","Epoch 38/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.3338\n","\n","Epoch 00038: loss improved from 1.34071 to 1.33377, saving model to model_weights_saved.hdf5\n","Epoch 39/100\n","1053/1053 [==============================] - 68s 65ms/step - loss: 1.3321\n","\n","Epoch 00039: loss improved from 1.33377 to 1.33213, saving model to model_weights_saved.hdf5\n","Epoch 40/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.3257\n","\n","Epoch 00040: loss improved from 1.33213 to 1.32574, saving model to model_weights_saved.hdf5\n","Epoch 41/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.3224\n","\n","Epoch 00041: loss improved from 1.32574 to 1.32245, saving model to model_weights_saved.hdf5\n","Epoch 42/100\n","1053/1053 [==============================] - 68s 65ms/step - loss: 1.3175\n","\n","Epoch 00042: loss improved from 1.32245 to 1.31754, saving model to model_weights_saved.hdf5\n","Epoch 43/100\n","1053/1053 [==============================] - 68s 65ms/step - loss: 1.3146\n","\n","Epoch 00043: loss improved from 1.31754 to 1.31456, saving model to model_weights_saved.hdf5\n","Epoch 44/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.3096\n","\n","Epoch 00044: loss improved from 1.31456 to 1.30964, saving model to model_weights_saved.hdf5\n","Epoch 45/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.3089\n","\n","Epoch 00045: loss improved from 1.30964 to 1.30893, saving model to model_weights_saved.hdf5\n","Epoch 46/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.3047\n","\n","Epoch 00046: loss improved from 1.30893 to 1.30474, saving model to model_weights_saved.hdf5\n","Epoch 47/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.3010\n","\n","Epoch 00047: loss improved from 1.30474 to 1.30101, saving model to model_weights_saved.hdf5\n","Epoch 48/100\n","1053/1053 [==============================] - 68s 65ms/step - loss: 1.2958\n","\n","Epoch 00048: loss improved from 1.30101 to 1.29577, saving model to model_weights_saved.hdf5\n","Epoch 49/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.2952\n","\n","Epoch 00049: loss improved from 1.29577 to 1.29518, saving model to model_weights_saved.hdf5\n","Epoch 50/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.2883\n","\n","Epoch 00050: loss improved from 1.29518 to 1.28830, saving model to model_weights_saved.hdf5\n","Epoch 51/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.2879\n","\n","Epoch 00051: loss improved from 1.28830 to 1.28786, saving model to model_weights_saved.hdf5\n","Epoch 52/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.2862\n","\n","Epoch 00052: loss improved from 1.28786 to 1.28616, saving model to model_weights_saved.hdf5\n","Epoch 53/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.2823\n","\n","Epoch 00053: loss improved from 1.28616 to 1.28232, saving model to model_weights_saved.hdf5\n","Epoch 54/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.5011\n","\n","Epoch 00054: loss did not improve from 1.28232\n","Epoch 55/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.3237\n","\n","Epoch 00055: loss did not improve from 1.28232\n","Epoch 56/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.2919\n","\n","Epoch 00056: loss did not improve from 1.28232\n","Epoch 57/100\n","1053/1053 [==============================] - 68s 65ms/step - loss: 1.2821\n","\n","Epoch 00057: loss improved from 1.28232 to 1.28214, saving model to model_weights_saved.hdf5\n","Epoch 58/100\n","1053/1053 [==============================] - 68s 65ms/step - loss: 1.2729\n","\n","Epoch 00058: loss improved from 1.28214 to 1.27286, saving model to model_weights_saved.hdf5\n","Epoch 59/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.2710\n","\n","Epoch 00059: loss improved from 1.27286 to 1.27101, saving model to model_weights_saved.hdf5\n","Epoch 60/100\n","1053/1053 [==============================] - 68s 65ms/step - loss: 1.2682\n","\n","Epoch 00060: loss improved from 1.27101 to 1.26819, saving model to model_weights_saved.hdf5\n","Epoch 61/100\n","1053/1053 [==============================] - 68s 65ms/step - loss: 1.2649\n","\n","Epoch 00061: loss improved from 1.26819 to 1.26488, saving model to model_weights_saved.hdf5\n","Epoch 62/100\n","1053/1053 [==============================] - 68s 65ms/step - loss: 1.2625\n","\n","Epoch 00062: loss improved from 1.26488 to 1.26249, saving model to model_weights_saved.hdf5\n","Epoch 63/100\n","1053/1053 [==============================] - 68s 65ms/step - loss: 1.2609\n","\n","Epoch 00063: loss improved from 1.26249 to 1.26090, saving model to model_weights_saved.hdf5\n","Epoch 64/100\n","1053/1053 [==============================] - 69s 66ms/step - loss: 1.2596\n","\n","Epoch 00064: loss improved from 1.26090 to 1.25964, saving model to model_weights_saved.hdf5\n","Epoch 65/100\n","1053/1053 [==============================] - 69s 66ms/step - loss: 1.2570\n","\n","Epoch 00065: loss improved from 1.25964 to 1.25698, saving model to model_weights_saved.hdf5\n","Epoch 66/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.2512\n","\n","Epoch 00066: loss improved from 1.25698 to 1.25124, saving model to model_weights_saved.hdf5\n","Epoch 67/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.2536\n","\n","Epoch 00067: loss did not improve from 1.25124\n","Epoch 68/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.2489\n","\n","Epoch 00068: loss improved from 1.25124 to 1.24895, saving model to model_weights_saved.hdf5\n","Epoch 69/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.2472\n","\n","Epoch 00069: loss improved from 1.24895 to 1.24719, saving model to model_weights_saved.hdf5\n","Epoch 70/100\n","1053/1053 [==============================] - 68s 65ms/step - loss: 1.2458\n","\n","Epoch 00070: loss improved from 1.24719 to 1.24575, saving model to model_weights_saved.hdf5\n","Epoch 71/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.2433\n","\n","Epoch 00071: loss improved from 1.24575 to 1.24334, saving model to model_weights_saved.hdf5\n","Epoch 72/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.2405\n","\n","Epoch 00072: loss improved from 1.24334 to 1.24051, saving model to model_weights_saved.hdf5\n","Epoch 73/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.2374\n","\n","Epoch 00073: loss improved from 1.24051 to 1.23739, saving model to model_weights_saved.hdf5\n","Epoch 74/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.2397\n","\n","Epoch 00074: loss did not improve from 1.23739\n","Epoch 75/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.2337\n","\n","Epoch 00075: loss improved from 1.23739 to 1.23372, saving model to model_weights_saved.hdf5\n","Epoch 76/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.2343\n","\n","Epoch 00076: loss did not improve from 1.23372\n","Epoch 77/100\n","1053/1053 [==============================] - 68s 65ms/step - loss: 1.2319\n","\n","Epoch 00077: loss improved from 1.23372 to 1.23185, saving model to model_weights_saved.hdf5\n","Epoch 78/100\n","1053/1053 [==============================] - 68s 65ms/step - loss: 1.2349\n","\n","Epoch 00078: loss did not improve from 1.23185\n","Epoch 79/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.2288\n","\n","Epoch 00079: loss improved from 1.23185 to 1.22883, saving model to model_weights_saved.hdf5\n","Epoch 80/100\n","1053/1053 [==============================] - 68s 65ms/step - loss: 1.2257\n","\n","Epoch 00080: loss improved from 1.22883 to 1.22569, saving model to model_weights_saved.hdf5\n","Epoch 81/100\n","1053/1053 [==============================] - 68s 65ms/step - loss: 1.2240\n","\n","Epoch 00081: loss improved from 1.22569 to 1.22398, saving model to model_weights_saved.hdf5\n","Epoch 82/100\n","1053/1053 [==============================] - 68s 65ms/step - loss: 1.2239\n","\n","Epoch 00082: loss improved from 1.22398 to 1.22387, saving model to model_weights_saved.hdf5\n","Epoch 83/100\n","1053/1053 [==============================] - 68s 65ms/step - loss: 1.2282\n","\n","Epoch 00083: loss did not improve from 1.22387\n","Epoch 84/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.2228\n","\n","Epoch 00084: loss improved from 1.22387 to 1.22285, saving model to model_weights_saved.hdf5\n","Epoch 85/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.2168\n","\n","Epoch 00085: loss improved from 1.22285 to 1.21683, saving model to model_weights_saved.hdf5\n","Epoch 86/100\n","1053/1053 [==============================] - 68s 65ms/step - loss: 1.2174\n","\n","Epoch 00086: loss did not improve from 1.21683\n","Epoch 87/100\n","1053/1053 [==============================] - 69s 66ms/step - loss: 1.2181\n","\n","Epoch 00087: loss did not improve from 1.21683\n","Epoch 88/100\n","1053/1053 [==============================] - 69s 66ms/step - loss: 1.2137\n","\n","Epoch 00088: loss improved from 1.21683 to 1.21374, saving model to model_weights_saved.hdf5\n","Epoch 89/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.2145\n","\n","Epoch 00089: loss did not improve from 1.21374\n","Epoch 90/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.2108\n","\n","Epoch 00090: loss improved from 1.21374 to 1.21085, saving model to model_weights_saved.hdf5\n","Epoch 91/100\n","1053/1053 [==============================] - 68s 65ms/step - loss: 1.2091\n","\n","Epoch 00091: loss improved from 1.21085 to 1.20908, saving model to model_weights_saved.hdf5\n","Epoch 92/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.2097\n","\n","Epoch 00092: loss did not improve from 1.20908\n","Epoch 93/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.2077\n","\n","Epoch 00093: loss improved from 1.20908 to 1.20775, saving model to model_weights_saved.hdf5\n","Epoch 94/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.2095\n","\n","Epoch 00094: loss did not improve from 1.20775\n","Epoch 95/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.2066\n","\n","Epoch 00095: loss improved from 1.20775 to 1.20663, saving model to model_weights_saved.hdf5\n","Epoch 96/100\n","1053/1053 [==============================] - 69s 66ms/step - loss: 1.2047\n","\n","Epoch 00096: loss improved from 1.20663 to 1.20468, saving model to model_weights_saved.hdf5\n","Epoch 97/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.2046\n","\n","Epoch 00097: loss improved from 1.20468 to 1.20455, saving model to model_weights_saved.hdf5\n","Epoch 98/100\n","1053/1053 [==============================] - 69s 66ms/step - loss: 1.2045\n","\n","Epoch 00098: loss improved from 1.20455 to 1.20447, saving model to model_weights_saved.hdf5\n","Epoch 99/100\n","1053/1053 [==============================] - 69s 66ms/step - loss: 1.2042\n","\n","Epoch 00099: loss improved from 1.20447 to 1.20423, saving model to model_weights_saved.hdf5\n","Epoch 100/100\n","1053/1053 [==============================] - 69s 65ms/step - loss: 1.2007\n","\n","Epoch 00100: loss improved from 1.20423 to 1.20066, saving model to model_weights_saved.hdf5\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7fd3f4395bd0>"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["#fit the model and let it train\n","model.fit(X,y,epochs=100,batch_size=256,callbacks=desired_callbacks)"]},{"cell_type":"code","execution_count":14,"id":"83503819","metadata":{"execution":{"iopub.execute_input":"2022-08-07T19:26:51.191144Z","iopub.status.busy":"2022-08-07T19:26:51.1907Z","iopub.status.idle":"2022-08-07T19:26:51.225775Z","shell.execute_reply":"2022-08-07T19:26:51.224585Z"},"papermill":{"duration":7.918242,"end_time":"2022-08-07T19:26:51.228608","exception":false,"start_time":"2022-08-07T19:26:43.310366","status":"completed"},"tags":[]},"outputs":[],"source":["#recompile the model with saved weights\n","filename='model_weights_saved.hdf5'\n","model.load_weights(filename)\n","model.compile(loss='categorical_crossentropy',optimizer='adam')"]},{"cell_type":"code","execution_count":15,"id":"0ebb6976","metadata":{"execution":{"iopub.execute_input":"2022-08-07T19:27:06.219113Z","iopub.status.busy":"2022-08-07T19:27:06.218624Z","iopub.status.idle":"2022-08-07T19:27:06.224432Z","shell.execute_reply":"2022-08-07T19:27:06.223153Z"},"papermill":{"duration":7.727987,"end_time":"2022-08-07T19:27:06.22721","exception":false,"start_time":"2022-08-07T19:26:58.499223","status":"completed"},"tags":[]},"outputs":[],"source":["# output of the models back into characters\n","num_to_char=dict((i,c) for i,c in enumerate(chars))"]},{"cell_type":"code","execution_count":16,"id":"da144840","metadata":{"execution":{"iopub.execute_input":"2022-08-07T19:27:22.76291Z","iopub.status.busy":"2022-08-07T19:27:22.762475Z","iopub.status.idle":"2022-08-07T19:27:22.77113Z","shell.execute_reply":"2022-08-07T19:27:22.769572Z"},"papermill":{"duration":7.903874,"end_time":"2022-08-07T19:27:22.775449","exception":false,"start_time":"2022-08-07T19:27:14.871575","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Random Seed :\n","\" spirit forbidden female followers muhammad lady died lessons indelibly impressed mind safie sickened \"\n"]}],"source":["#random seed to help generate\n","start=numpy.random.randint(0,len(x_data)-1)\n","pattern=x_data[start]\n","print(\"Random Seed :\")\n","print(\"\\\"\",''.join([num_to_char[value] for value in pattern]),\"\\\"\")"]},{"cell_type":"code","execution_count":17,"id":"b1762bcc","metadata":{"execution":{"iopub.execute_input":"2022-08-07T19:27:37.765912Z","iopub.status.busy":"2022-08-07T19:27:37.765062Z","iopub.status.idle":"2022-08-07T19:28:42.550611Z","shell.execute_reply":"2022-08-07T19:28:42.54917Z"},"papermill":{"duration":77.976095,"end_time":"2022-08-07T19:28:47.926052","exception":false,"start_time":"2022-08-07T19:27:29.949957","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":[" father said shall considerable surprised strange considerable suspect gutp www gutenberg tm electronic works project gutenberg tm electronic works project gutenberg tm electronic works project gutenberg tm electronic works project gutenberg tm electronic works project gutenberg tm electronic works project gutenberg tm electronic works project gutenberg tm electronic works project gutenberg tm electronic works project gutenberg tm electronic works project gutenberg tm electronic works project gutenberg tm electronic works project gutenberg tm electronic works project gutenberg tm electronic works project gutenberg tm electronic works project gutenberg tm electronic works project gutenberg tm electronic works project gutenberg tm electronic works project gutenberg tm electronic works project gutenberg tm electronic works project gutenberg tm electronic works project gutenberg tm electronic works project gutenberg tm electronic works project gutenberg tm electronic works project gutenber"]}],"source":["# generate the text\n","for i in range(1000):\n","    x=numpy.reshape(pattern,(1,len(pattern),1))\n","    x=x/float(vocab_len)\n","    prediction=model.predict(x, verbose=0)\n","    index=numpy.argmax(prediction)\n","    result=num_to_char[index]\n","    seg_in=[num_to_char[value] for value in pattern]\n","    sys.stdout.write(result)\n","    pattern.append(index)\n","    pattern=pattern[1:len(pattern)]"]},{"cell_type":"markdown","id":"4188e0b7","metadata":{"papermill":{"duration":7.642644,"end_time":"2022-08-07T19:29:03.116076","exception":false,"start_time":"2022-08-07T19:28:55.473432","status":"completed"},"tags":[]},"source":["The End"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":7128.861845,"end_time":"2022-08-07T19:29:13.998361","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-08-07T17:30:25.136516","version":"2.3.4"}},"nbformat":4,"nbformat_minor":5}